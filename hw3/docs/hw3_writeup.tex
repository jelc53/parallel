\documentclass[12pt,letterpaper,twoside]{article}

\newif\ifsolution\solutiontrue   % Include the solutions
%\newif\ifsolution\solutionfalse  % Exclude the solutions

\usepackage{cme213}
\usepackage{xcolor}
\usepackage{graphicx}

\newcommand{\T}[1]{\text{\texttt{#1}}}
\newcommand{\V}[1]{\text{\textit{#1}}}

\begin{document}

{\centering \textbf{Homework 3\\ Due Sunday, May 1st via GradeScope\\}}
\vspace*{-8pt}\noindent\rule{\linewidth}{1pt}

\paragraph{Problem 1: Recurrence } Implement a simple CUDA program for 
a recurrence relation (inspired by the Mandelbrot Set) for many 
different starting points.

\begin{itemize}
    \item \textbf{1.1 Allocate GPU memory} Idea: Use \texttt{cudaMalloc}
    to allocate memory on the GPU device for both the input and output 
    arrays we will need for the recurrence implementation. Free memory 
    with \texttt{cudaFree} at end of \texttt{main()}.

    \begin{cpp}
        // Allocate num_bytes of memory to the device arrays
        cudaMalloc(&device_input_array, num_bytes);
        cudaMalloc(&device_output_array, num_bytes);
        ...
        ...

        // Deallocate memory from both device arrays
        cudaFree(device_input_array);
        cudaFree(device_output_array);
    \end{cpp}

    \item \textbf{1.2 Initialize array of random floats} Idea: Use in-built
    rand() functor from the standard cpp library and scale it between -1 
    and 1 as required.

    \begin{cpp}
        // Initialize an array of size arr_size in input_array with 
        //random floats between -1 and 1
        void initialize_array(vec &input_array, size_t arr_size) {
          input_array.resize(arr_size);
          std::generate(input_array.begin(), input_array.end(), rand);
        
          for(int i=0; i<arr_size; i++){
            input_array[i] = static_cast<float>(input_array[i])/
                                (RAND_MAX/2)-1;
          }    
        }
    \end{cpp}

    \item \textbf{1.3 Implement recurrence kernel} Idea: Recurrence operations 
    themselves are not independent and therefore not parallelizable, however, 
    we can parallelize doing many of these recurrence loops for different 
    starting points (constants). So, we want to parallelize over our 1-dim 
    input array of constants.

    Since our kernel needs to handle cases where the number of threads is less 
    than the number of entries in our input array, we need to use a grid-stride 
    loop.

    \begin{cpp}
    /**
    * Implement the kernel recurrence.
    * The CPU implementation is in host_recurrence() in main_q1.cu.
    */
    __global__ void recurrence(const elem_type* input_array,
                               elem_type* output_array, 
                               size_t num_iter,
                               size_t array_length) {

        for (int xid = blockIdx.x * blockDim.x + threadIdx.x;
            xid < array_length;
            xid += blockDim.x * gridDim.x) {
        
            elem_type z = 0;
            elem_type constant = input_array[xid];

            int it=0;
            while(it<num_iter) {
            z = z * z + constant;
            it++;
            }
            output_array[xid] = z;
        }
    }
    \end{cpp}
    
    Console logs.
\begin{verbatim}
Starting at Fri Apr 29 00:28:45 UTC 2022

nvcc -O3 -std=c++11 -arch=compute_75 -code=sm_75 -o main_q1 main_q1.cu

Output from main_q1
----------------
Largest error found at pos: 15 error 7.81565e-08 
    expected 1.52526 and got 1.52526

Largest error found at pos: 0 error 0 
    expected 0.680375 and got 0.680375

Largest error found at pos: 439038 error 1.19193e-07 
    expected 1.00014 and got 1.00014

Largest error found at pos: 142710 error 2.38333e-07 
    expected 2.00072 and got 2.00072

Largest error found at pos: 482709 error 5.61004e-07 
    expected 16.9994 and got 16.9994

Largest error found at pos: 482709 error 1.15797e-06 
    expected 289.897 and got 289.898

Largest error found at pos: 482709 error 2.324e-06 
    expected 84041.4 and got 84041.6

Largest error found at pos: 482709 error 4.63941e-06 
    expected 7.06296e+09 and got 7.063e+09

Largest error found at pos: 482709 error 9.25711e-06 
    expected 4.98854e+19 and got 4.98859e+19

Largest error found at pos: 138972 error 1.79297e-05 
    expected 8.03779e+21 and got 8.03765e+21

Largest error found at pos: 905817 error 2.59306e-05 
    expected 1.66519e+35 and got 1.66523e+35

Questions 1.1-1.3: your code passed all the tests!
\end{verbatim}

    \item \textbf{1.4 Vary number of threads per block} ... 
    Many threads concurrently trying to access cache (traffic)

    \begin{figure}[h]
        \center
        \includegraphics[scale=0.7]{q1_4.png}
        \caption{Performance as we vary number of threads per block}
    \end{figure}

    \item \textbf{1.5 Vary number of blocks}

    \begin{figure}[h]
        \center
        \includegraphics[scale=0.7]{q1_5.png}
        \caption{Performance as we vary number of blocks}
    \end{figure}

    \item \textbf{1.6 Vary number of iterations}

    \begin{figure}[h]
        \center
        \includegraphics[scale=0.7]{q1_6.png}
        \caption{Performance as we vary number of iterations}
    \end{figure}
    
\end{itemize}


\paragraph{Problem 2: PageRank} ...

\begin{itemize}
    \item \textbf{2.1: ...} ...


\end{itemize}


Submission information logs.
\begin{verbatim}
jelc@cardinal1:~$ /afs/ir.stanford.edu/class/cme213/script/submit.py hw2 private/cme213-jelc53/hw2
Submission for assignment 'hw2' as user 'jelc'
Attempt 1/10
Time stamp: 2022-04-13 20:09
List of files being copied:
    private/cme213-jelc53/hw2/sum.h	 [768 bytes]
    private/cme213-jelc53/hw2/parallel_radix_sort.h	 [7625 bytes]

Your files were copied successfully.
Directory where files were copied: /afs/ir.stanford.edu/class/cme213/submissions/hw2/jelc/1
List of files in this directory:
    sum.h	 [768 bytes]
    parallel_radix_sort.h	 [7625 bytes]
    metadata	 [137 bytes]

This completes the submission process. Thank you!

jelc@cardinal1:~$ ls /afs/ir.stanford.edu/class/cme213/submissions/hw2/jelc/1
metadata  parallel_radix_sort.h  sum.h
\end{verbatim}

\end{document}
